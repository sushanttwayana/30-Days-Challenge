{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOs8/V1C8SVqurLF1xvkzYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushanttwayana/30-Days-Challenge/blob/main/Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter tuning with GridSearchCV**\n",
        "\n",
        "Import GridSearchCV.\n",
        "\n",
        "Set up a parameter grid for \"alpha\", using np.linspace() to create 20 evenly spaced values ranging from 0.00001 to 1.\n",
        "\n",
        "Call GridSearchCV(), passing lasso, the parameter grid, and setting cv equal to kf.\n",
        "\n",
        "Fit the grid search object to the training data to perform a cross-validated grid search."
      ],
      "metadata": {
        "id": "W7mRG7uCdRjG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqChLam1alfv"
      },
      "outputs": [],
      "source": [
        "# Import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Set up the parameter grid\n",
        "param_grid = {\"alpha\": np.linspace(0.00001, 1, 20)}\n",
        "\n",
        "# Instantiate lasso_cv\n",
        "lasso_cv = GridSearchCV(lasso, param_grid, cv=kf)\n",
        "\n",
        "# Fit to the training data\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "print(\"Tuned lasso paramaters: {}\".format(lasso_cv.best_params_))\n",
        "print(\"Tuned lasso score: {}\".format(lasso_cv.best_score_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuned lasso paramaters: {'alpha': 1e-05}\n",
        "\n",
        "Tuned lasso score: 0.33078807238121977"
      ],
      "metadata": {
        "id": "pqW6SO-Zasse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, the best model only has an R-squared score of 0.33, highlighting that using the optimal hyperparameters does not guarantee a high performing model!"
      ],
      "metadata": {
        "id": "S0zsaK-ya5Kd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter tuning with RandomizedSearchCV**\n",
        "\n",
        "GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space. In this case, you can use RandomizedSearchCV, which tests a fixed number of hyperparameter settings from specified probability distributions.\n",
        "\n",
        "\n",
        "Create params, adding \"l1\" and \"l2\" as penalty values, setting C to a range of 50 float values between 0.1 and 1.0, and class_weight to either \"balanced\" or a dictionary containing 0:0.8, 1:0.2.\n",
        "\n",
        "Create the Randomized Search CV object, passing the model and the parameters, and setting cv equal to kf.\n",
        "\n",
        "Fit logreg_cv to the training data.\n",
        "\n",
        "Print the model's best parameters and accuracy score."
      ],
      "metadata": {
        "id": "2fHLuWwsdpW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Create the parameter space\n",
        "params = {\"penalty\": [\"l1\", \"l2\"],\n",
        "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
        "         \"C\": np.linspace(0.1, 1.0, 50),\n",
        "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
        "\n",
        "# Instantiate the RandomizedSearchCV object\n",
        "logreg = LogisticRegression()\n",
        "logreg_cv = RandomizedSearchCV(logreg,params, cv=kf)\n",
        "\n",
        "# Fit the data to the model\n",
        "logreg_cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
        "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))"
      ],
      "metadata": {
        "id": "xGEBglNcatNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Tuned Logistic Regression Parameters: {'tol': 0.14294285714285712, 'penalty': 'l2', 'class_weight': 'balanced', 'C': 0.6326530612244898}\n",
        "\n",
        "  Tuned Logistic Regression Best Accuracy Score: 0.7460082633613221"
      ],
      "metadata": {
        "id": "EgX9EsXCdddN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eabwpTEBeFm1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
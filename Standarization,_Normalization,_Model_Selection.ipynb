{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNojHFwivhcvN3nbd4CBZlq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushanttwayana/30-Days-Challenge/blob/main/Standarization%2C_Normalization%2C_Model_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Centering and scaling for regression\n",
        "Now you have seen the benefits of scaling your data, you will use a pipeline to preprocess the music_df features and build a lasso regression model to predict a song's loudness.\n",
        "\n",
        "X_train, X_test, y_train, and y_test have been created from the music_df dataset, where the target is \"loudness\" and the features are all other columns in the dataset. Lasso and Pipeline have also been imported for you.\n",
        "\n",
        "Note that \"genre\" has been converted to a binary feature where 1 indicates a rock song, and 0 represents other genres.\n",
        "\n",
        "Import StandardScaler.\n",
        "\n",
        "Create the steps for the pipeline object, a StandardScaler object called \"scaler\", and a lasso model called \"lasso\" with alpha set to 0.5.\n",
        "\n",
        "Instantiate a pipeline with steps to scale and build a lasso regression model.\n",
        "\n",
        "Calculate the R-squared value on the test data."
      ],
      "metadata": {
        "id": "Laezr5fTf0Or"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmszjzMvewDE"
      },
      "outputs": [],
      "source": [
        "# Import StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create pipeline steps\n",
        "steps = [(\"scaler\", StandardScaler()),\n",
        "         (\"lasso\", Lasso(alpha=0.5))]\n",
        "\n",
        "# Instantiate the pipeline\n",
        "pipeline = Pipeline(steps)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Calculate and print R-squared\n",
        "print(pipeline.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<script.py> output:\n",
        "    0.6193523316282489\n",
        "\n",
        "The model may have only produced an R-squared of 0.619, but without scaling this exact model would have only produced a score of 0.35, which proves just how powerful scaling can be!"
      ],
      "metadata": {
        "id": "BvIuLZVkf3XA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Centering and scaling for classification**\n",
        "\n",
        "Now you will bring together scaling and model building into a pipeline for cross-validation.\n",
        "\n",
        "our task is to build a pipeline to scale features in the music_df dataset and perform grid search cross-validation using a logistic regression model with different values for the hyperparameter C. The target variable here is \"genre\", which contains binary values for rock as 1 and any other genre as 0.\n",
        "\n",
        "StandardScaler, LogisticRegression, and GridSearchCV have all been imported .\n",
        "\n",
        "Build the steps for the pipeline: a StandardScaler() object named \"scaler\", and a logistic regression model named \"logreg\".\n",
        "\n",
        "Create the parameters, searching 20 equally spaced float values ranging from 0.001 to 1.0 for the logistic regression model's C hyperparameter within the pipeline.\n",
        "\n",
        "Instantiate the grid search object.\n",
        "\n",
        "Fit the grid search object to the training data."
      ],
      "metadata": {
        "id": "q6hrqlKahOMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the steps\n",
        "steps = [(\"scaler\", StandardScaler()),\n",
        "         (\"logreg\", LogisticRegression())]\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "# Create the parameter space\n",
        "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=21)\n",
        "\n",
        "# Instantiate the grid search object\n",
        "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
        "\n",
        "# Fit to the training data\n",
        "cv.fit(X_train, y_train)\n",
        "print(cv.best_score_, \"\\n\", cv.best_params_)"
      ],
      "metadata": {
        "id": "vvdhy-cogGjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<script.py> output:\n",
        "    0.8425\n",
        "     {'logreg__C': 0.1061578947368421}\n",
        "\n",
        "   Using a pipeline shows that a logistic regression model with \"C\" set to approximately 0.1 produces a model with 0.8425 accuracy!"
      ],
      "metadata": {
        "id": "98hEWujXhddw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing regression model performance\n",
        "\n",
        "Now you have seen how to evaluate multiple models out of the box, you will build three regression models to predict a song's \"energy\" levels.\n",
        "\n",
        "The music_df dataset has had dummy variables for \"genre\" added. Also, feature and target arrays have been created, and these have been split into X_train, X_test, y_train, and y_test.\n",
        "\n",
        "The following have been imported for you: LinearRegression, Ridge, Lasso, cross_val_score, and KFold.\n",
        "\n",
        "Write a for loop using model as the iterator, and model.values() as the iterable.\n",
        "\n",
        "Perform cross-validation on the training features and the training target array using the model, setting cv equal to the KFold object.\n",
        "\n",
        "Append the model's cross-validation scores to the results list.\n",
        "\n",
        "Create a box plot displaying the results, with the x-axis labels as the names of the models."
      ],
      "metadata": {
        "id": "KuoF7JsThkPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
        "results = []\n",
        "\n",
        "# Loop through the models' values\n",
        "for model in models.values():\n",
        "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
        "\n",
        "  # Perform cross-validation\n",
        "  cv_scores =cross_val_score(model, X_train, y_train, cv=kf)\n",
        "\n",
        "  # Append the results\n",
        "  results.append(cv_scores)\n",
        "\n",
        "# Create a box plot of the results\n",
        "plt.boxplot(results, labels=models.keys())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WldNBxn7hjsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso regression is not a good model for this problem, while linear regression and ridge perform fairly equally. Let's make predictions on the test set, and see if the RMSE can guide us on model selection."
      ],
      "metadata": {
        "id": "jVgTeGrCkmPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting on the test set\n",
        "\n",
        "In the last exercise, linear regression and ridge appeared to produce similar results. It would be appropriate to select either of those models; however, you can check predictive performance on the test set to see if either one can outperform the other.\n",
        "\n",
        "You will use root mean squared error (RMSE) as the metric. The dictionary models, containing the names and instances of the two models, has been preloaded for you along with the training and target arrays X_train_scaled, X_test_scaled, y_train, and y_test.\n",
        "\n",
        "Import mean_squared_error.\n",
        "\n",
        "Fit the model to the scaled training features and the training labels.\n",
        "Make predictions using the scaled test features.\n",
        "\n",
        "Calculate RMSE by passing the test set labels and the predicted labels.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lQVxiTtAl-Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "  # Fit the model to the training data\n",
        "  model.fit(X_train_scaled,y_train)\n",
        "\n",
        "  # Make predictions on the test set\n",
        "  y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "  # Calculate the test_rmse\n",
        "  test_rmse = mean_squared_error(y_test, y_pred, squared= False)\n",
        "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
      ],
      "metadata": {
        "id": "WMEXgEinkmyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Linear Regression Test Set RMSE: 0.11988851505947569\n",
        "    Ridge Test Set RMSE: 0.11987066103299668\n",
        "\n",
        "  The linear regression model just edges the best performance, although the difference is a RMSE of 0.00001 for popularity! Now let's look at classification model selection."
      ],
      "metadata": {
        "id": "LRitI7I1mKEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing classification model performance\n",
        "\n",
        "In this exercise, you will be solving a classification problem where the \"popularity\" column in the music_df dataset has been converted to binary values, with 1 representing popularity more than or equal to the median for the \"popularity\" column, and 0 indicating popularity below the median.\n",
        "\n",
        "Your task is to build and visualize the results of three different models to classify whether a song is popular or not.\n",
        "\n",
        "The data has been split, scaled, and preloaded for you as X_train_scaled, X_test_scaled, y_train, and y_test. Additionally, KNeighborsClassifier, DecisionTreeClassifier, and LogisticRegression have been imported.\n",
        "\n",
        "Create a dictionary of \"Logistic Regression\", \"KNN\", and \"Decision Tree Classifier\", setting the dictionary's values to a call of each model.\n",
        "Loop through the values in models.\n",
        "Instantiate a KFold object to perform 6 splits, setting shuffle to True and random_state to 12.\n",
        "Perform cross-validation using the model, the scaled training features, the target training set, and setting cv equal to kf."
      ],
      "metadata": {
        "id": "JeKDI8-hmNYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create models dictionary\n",
        "models = {\"Logistic Regression\": LogisticRegression(), \"knn\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
        "results = []\n",
        "\n",
        "# Loop through the models' values\n",
        "for model in models.values():\n",
        "\n",
        "  # Instantiate a KFold object\n",
        "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
        "\n",
        "  # Perform cross-validation\n",
        "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
        "  results.append(cv_results)\n",
        "plt.boxplot(results, labels=models.keys())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SvhulY9LnUCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like logistic regression is the best candidate based on the cross-validation results! Let's wrap up by building a pipeline"
      ],
      "metadata": {
        "id": "GpaxB06XnVXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline for predicting song popularity\n",
        "\n",
        "For the final exercise, you will build a pipeline to impute missing values, scale features, and perform hyperparameter tuning of a logistic regression model. The aim is to find the best parameters and accuracy when predicting song genre!\n",
        "\n",
        "All the models and objects required to build the pipeline have been preloaded for you.\n",
        "\n",
        "Create the steps for the pipeline by calling a simple imputer, a standard scaler, and a logistic regression model.\n",
        "\n",
        "Create a pipeline object, and pass the steps variable.\n",
        "\n",
        "Instantiate a grid search object to perform cross-validation using the pipeline and the parameters.\n",
        "\n",
        "Print the best parameters and compute and print the test set accuracy score for the grid search object."
      ],
      "metadata": {
        "id": "d2UPpxMDo7xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create steps\n",
        "steps = [(\"imp_mean\", SimpleImputer()),\n",
        "         (\"scaler\", StandardScaler()),\n",
        "         (\"logreg\", LogisticRegression())]\n",
        "\n",
        "# Set up pipeline\n",
        "pipeline = Pipeline(steps)\n",
        "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
        "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "tuning = GridSearchCV(pipeline, param_grid=params)\n",
        "tuning.fit(X_train, y_train)\n",
        "y_pred = tuning.predict(X_test)\n",
        "\n",
        "# Compute and print performance\n",
        "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))\n"
      ],
      "metadata": {
        "id": "ahejGusCn7S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you've selected a model, built a preprocessing pipeline, and performed hyperparameter tuning to create a model that is 82% accurate in predicting song genres!\n",
        "\n",
        "<script.py> output:\n",
        "    Tuned Logistic Regression Parameters: {'logreg__C': 0.112, 'logreg__solver': 'newton-cg'}, Accuracy: 0.82"
      ],
      "metadata": {
        "id": "ym_3wqwbpsrj"
      }
    }
  ]
}